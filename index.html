
<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>The nuts and bolts of Uncertainty Quantification</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Organizers" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="CVPR 2021 Tutorial" />
<meta property="og:description" content="CVPR 2021 Tutorial" />
<link rel="canonical" href="https://audio-visual-scene-understanding.github.io/" />
<meta property="og:url" content="https://audio-visual-scene-understanding.github.io/" />
<meta property="og:site_name" content="Audio-Visual Scene Understanding" />
<script type="application/ld+json">
{"description":"WACV 2024 Tutorial","@type":"WebSite","url":"https://uqtutorial.github.io/","name":"Uncertainty Quantification Tutorial","headline":"The nuts and bolts of Uncertainty Quantification"}</script>
<!-- End Jekyll SEO tag -->

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <link rel="stylesheet" href="/assets/css/style.css?v=6630701df1d052c81ea810d987f1f29fdd76c5ad">
    <link rel="stylesheet" href="/assets/mystyle.css">


  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">The nuts and bolts of Uncertainty Quantification</h1>
      <h2 class="project-tagline">WACV 2024<br>Time: January XX </h2>
      
      
      
    </section>

<!--    <section class="main-content">
       <h2 id="organizers">Organizers</h2>
 -->


<!--
 <div class="containertext">
  <h2 style="text-align: center">News</h2>
    <p>A survey on the audio-visual learning is released based on this tutorial.
     <a href="https://gewu-lab.github.io/audio-visual-learning/"  target="_blank">[Website]</a>, 
     <a href="https://arxiv.org/abs/2208.09579"  target="_blank">[arXiv]</a>
    </p>
</div> 


<div class="containertext">
  <h2 style="text-align: center">Overview</h2>
    <p>Sight and hearing are two of the most important senses for human perception. From cognitive perspective, the visual and auditory information is actually slightly discrepant, but the percept is unified with multisensory integration. Whatâ€™s more, when there are multiple input senses, human reactions usually perform more exactly or efficiently than single sense. Inspired by this, for computational models, our community has begun to explore marrying computer vision with audition, and targets to address some essential problems of audio-visual learning then further develops them into interesting and worthwhile tasks. In recent years, we were delighted to witness many developments in learning from both visual and auditory data.
    </p>
    <p>This tutorial aims to cover recent advances in audio-visual learning, from the neuroscience study of humans to the computation models of machine. For each research sub-topic, we will give a concrete introduction of the contained problems/tasks, and the current research progress as well as the open problems. We hope the audience, not only the graduate students but also the researchers new in this area, can benefit from this tutorial and learn the principle problems and cutting-edge approaches of audio-visual learning.
    </p>
    </p>
</div> 

<br>



<div class="container">
  <h2>Schedule</h2>

  <div class="tab ">
    <button class="tablinks">Time Zone:</button>
    <button id="default_button" class="tablinks" onclick="openCity(event, 'EST')">N. America (East)</button>
    <button class="tablinks" onclick="openCity(event, 'CST')">China/Singapore</button>
    <button class="tablinks" onclick="openCity(event, 'CET')">Europe (Central)</button>
  </div>

  <div  id="EST" class="tabcontent" style ="width:100% ">
    <table class="alt">
        <tbody>
            <col width="18%">
            <col width="39%">
            <col width="23%">
            <col width="20%">
            <tr>
                <td><span class="announce_date">10:00 - 10:05</span></td>
                <td class="tabletext" style="text-align: left">Welcome</td>
                <td class="tabletext"><a href="https://zenodo.org/record/5013725/files/Welcome.pptx?download=1"  target="_blank">[Slides]</a></td>
                <td class="tabletext"><a href="https://www.cs.rochester.edu/~cxu22/"  target="_blank">Chenliang Xu</a></td>
            </tr>
            <tr>
              <td><span class="announce_date">10:05 - 10:55</span></td>
              <td class="tabletext" style="text-align: left">  Neuroscience in audio-visual perception</td>
              <td class="tabletext"><a href="https://zenodo.org/record/5013725/files/Neuroscience%20in%20audio-visual%20perception.pptx?download=1"  target="_blank">[Slides]</a>&nbsp<a href="https://zenodo.org/record/5078845/files/ross.mp4?download=1"  target="_blank">[Recording]</a></td>
              <td class="tabletext"><a href="https://www.urmc.rochester.edu/labs/maddox.aspx"  target="_blank">Ross K. Maddox</a></td>
          </tr>
          <tr>
            <td><span class="announce_date">10:55 - 11:45</span></td>
            <td class="tabletext" style="text-align: left">Audio scene understanding</td>
            <td class="tabletext"><a href="https://zenodo.org/record/5013725/files/Audio%20scene%20understanding.pdf?download=1"  target="_blank">[Slides]</a>&nbsp<a href="https://zenodo.org/record/5078889/files/zhiyao.mp4?download=1"  target="_blank">[Recording]</a></td>
            <td class="tabletext"><a href="http://www2.ece.rochester.edu/~zduan/"  target="_blank">Zhiyao Duan</a></td>
        </tr>
        <tr>
          <td><span class="announce_date">11:45 - 12:35</span></td>
          <td class="tabletext" style="text-align: left">Audio visual scene-aware dialog based on human perspective scene understanding</td>
          <td class="tabletext"><a href="https://zenodo.org/record/5077829/files/Human-perspective_Scene-understanding%40CVPR2021-open.pdf?download=1"  target="_blank">[Slides]</a>&nbsp<a href="https://zenodo.org/record/5078937/files/chiori.mp4?download=1"  target="_blank">[Recording]</a></td>
          <td class="tabletext" ><a href="https://www.merl.com/people/chori"  target="_blank">Chiori Hori</a></td>
        </tr>
        <tr>
          <td><span class="announce_date">12:35 - 13:25</span></td>
          <td class="tabletext" style="text-align: left">Audio-visual self-supervised learning</td>
          <td class="tabletext"><a href="https://zenodo.org/record/5013725/files/Audio-visual%20self-supervised%20learning.pdf?download=1"  target="_blank">[Slides]</a>&nbsp<a href="https://zenodo.org/record/5078950/files/di.mp4?download=1"  target="_blank">[Recording]</a></td>
          <td class="tabletext"><a href="https://dtaoo.github.io/"  target="_blank">Di Hu</a></td>
        </tr>
        <tr>
          <td><span class="announce_date">13:25 - 13:40</span></td>
          <td class="tabletext" style="text-align: left">Coffee Break</td>
          <td></td>
          <td class="tabletext"></td>
        </tr>
        <tr>
          <td><span class="announce_date">13:40 - 14:30</span></td>
          <td class="tabletext" style="text-align: left">Natural interaction with audiovisual messages</td>
          <td class="tabletext"><a href="https://zenodo.org/record/5077833/files/CVPR_Amir_Main.pdf?download=1"  target="_blank">[Slides]</a>&nbsp<a href="https://zenodo.org/record/5078610/files/amir.mp4?download=1"  target="_blank">[Recording]</a></td>
          <td class="tabletext"><a href="https://www.amir-zadeh.com/"  target="_blank">Amir Zadeh</a></td>
        </tr>
        <tr>
          <td><span class="announce_date">14:30 - 15:20</span></td>
          <td class="tabletext" style="text-align: left">Audio-visual sound source localization and separation</td>
          <td class="tabletext"><a href="https://zenodo.org/record/5078654/files/chuang.mp4?download=1"  target="_blank">[Recording]</a></td>
          <td class="tabletext"><a href="https://people.csail.mit.edu/ganchuang/"  target="_blank">Chuang Gan</a></td>
        </tr>
        <tr>
          <td><span class="announce_date">15:20 - 16:10</span></td>
          <td class="tabletext" style="text-align: left">Audio-visual cross-modal generation</td>
          <td class="tabletext"><a href="https://zenodo.org/record/5013725/files/Audio-visual%20cross-modal%20generation.pptx?download=1"  target="_blank">[Slides]</a>&nbsp<a href="https://zenodo.org/record/5078731/files/lele.mp4?download=1"  target="_blank">[Recording]</a></td>
          <td class="tabletext"><a href="https://www.cs.rochester.edu/u/lchen63/"  target="_blank">Lele Chen</a></td>
        </tr>
        <tr>
          <td><span class="announce_date">16:10 - 17:00</span></td>
          <td class="tabletext" style="text-align: left">Audio-visual video understanding</td>
          <td class="tabletext"><a href="https://zenodo.org/record/5013725/files/Audio-visual%20video%20understanding.pptx?download=1"  target="_blank">[Slides]</a>&nbsp<a href="https://zenodo.org/record/5078777/files/yapeng.mp4?download=1"  target="_blank">[Recording]</a></td>
          <td class="tabletext"><a href="http://yapengtian.org/"  target="_blank">Yapeng Tian</a></td>
        </tr>
        <tr>
          <td><span class="announce_date">17:00 - 17:30</span></td>
          <td class="tabletext" style="text-align: left">Panel Discussion</td>
          <td class="tabletext"><a href="https://zenodo.org/record/5078801/files/discussion.mp4?download=1"  target="_blank">[Recording]</a></td>
          <td></td>
        </tr>
  
  
    </tbody>
  </table>
  </div>
  
  <div  id="CST" class="tabcontent" style ="width:100%">
    <table class="alt">
        <tbody>
          <col width="18%">
          <col width="39%">
          <col width="23%">
          <col width="20%">
            <tr>
                <td><span class="announce_date">22:00 - 22:05</span></td>
                <td class="tabletext" style="text-align: left">Welcome</td>
                <td class="tabletext"><a href="https://zenodo.org/record/5013725/files/Welcome.pptx?download=1"  target="_blank">[Slides]</a></td>
                <td class="tabletext"><a href="https://www.cs.rochester.edu/~cxu22/"  target="_blank">Chenliang Xu</a></td>
            </tr>
            <tr>
              <td><span class="announce_date">22:05 - 22:55</span></td>
              <td class="tabletext" style="text-align: left">  Neuroscience in audio-visual perception</td>
              <td class="tabletext"><a href="https://zenodo.org/record/5013725/files/Neuroscience%20in%20audio-visual%20perception.pptx?download=1"  target="_blank">[Slides]</a>&nbsp<a href="https://zenodo.org/record/5078845/files/ross.mp4?download=1"  target="_blank">[Recording]</a></td>
              <td class="tabletext"><a href="https://www.urmc.rochester.edu/labs/maddox.aspx"  target="_blank">Ross K. Maddox</a></td>
          </tr>
          <tr>
            <td><span class="announce_date">22:55 - 23:45</span></td>
            <td class="tabletext" style="text-align: left">Audio scene understanding</td>
            <td class="tabletext"><a href="https://zenodo.org/record/5013725/files/Audio%20scene%20understanding.pdf?download=1"  target="_blank">[Slides]</a>&nbsp<a href="https://zenodo.org/record/5078889/files/zhiyao.mp4?download=1"  target="_blank">[Recording]</a></td>
            <td class="tabletext"><a href="http://www2.ece.rochester.edu/~zduan/"  target="_blank">Zhiyao Duan</a></td>
        </tr>
        <tr>
          <td><span class="announce_date">23:45 - 00:35 (Day+1)</span></td>
          <td class="tabletext" style="text-align: left">Audio visual scene-aware dialog based on human perspective scene understanding</td>
          <td class="tabletext"><a href="https://zenodo.org/record/5077829/files/Human-perspective_Scene-understanding%40CVPR2021-open.pdf?download=1"  target="_blank">[Slides]</a>&nbsp<a href="https://zenodo.org/record/5078937/files/chiori.mp4?download=1"  target="_blank">[Recording]</a></td>
          <td class="tabletext" ><a href="https://www.merl.com/people/chori"  target="_blank">Chiori Hori</a></td>
        </tr>
        <tr>
          <td><span class="announce_date">00:35 - 01:25 (Day+1)</span></td>
          <td class="tabletext" style="text-align: left">Audio-visual self-supervised learning</td>
          <td class="tabletext"><a href="https://zenodo.org/record/5013725/files/Audio-visual%20self-supervised%20learning.pdf?download=1"  target="_blank">[Slides]</a>&nbsp<a href="https://zenodo.org/record/5078950/files/di.mp4?download=1"  target="_blank">[Recording]</a></td>
          <td class="tabletext"><a href="https://dtaoo.github.io/"  target="_blank">Di Hu</a></td>
        </tr>
        <tr>
          <td><span class="announce_date">01:25 - 01:40 (Day+1)</span></td>
          <td class="tabletext" style="text-align: left">Coffee Break</td>
          <td></td>
          <td class="tabletext"></td>
        </tr>
        <tr>
          <td><span class="announce_date">01:40 - 02:30 (Day+1)</span></td>
          <td class="tabletext" style="text-align: left">Natural interaction with audiovisual messages</td>
          <td class="tabletext"><a href="https://zenodo.org/record/5077833/files/CVPR_Amir_Main.pdf?download=1"  target="_blank">[Slides]</a>&nbsp<a href="https://zenodo.org/record/5078610/files/amir.mp4?download=1"  target="_blank">[Recording]</a></td>
          <td class="tabletext"><a href="https://www.amir-zadeh.com/"  target="_blank">Amir Zadeh</a></td>
        </tr>
        <tr>
          <td><span class="announce_date">02:30 - 03:20 (Day+1)</span></td>
          <td class="tabletext" style="text-align: left">Audio-visual sound source localization and separation</td>
          <td class="tabletext"><a href="https://zenodo.org/record/5078654/files/chuang.mp4?download=1"  target="_blank">[Recording]</a></td>
          <td class="tabletext"><a href="https://people.csail.mit.edu/ganchuang/"  target="_blank">Chuang Gan</a></td>
        </tr>
        <tr>
          <td><span class="announce_date">03:20 - 04:10 (Day+1)</span></td>
          <td class="tabletext" style="text-align: left">Audio-visual cross-modal generation</td>
          <td class="tabletext"><a href="https://zenodo.org/record/5013725/files/Audio-visual%20cross-modal%20generation.pptx?download=1"  target="_blank">[Slides]</a>&nbsp<a href="https://zenodo.org/record/5078731/files/lele.mp4?download=1"  target="_blank">[Recording]</a></td>
          <td class="tabletext"><a href="https://www.cs.rochester.edu/u/lchen63/"  target="_blank">Lele Chen</a></td>
        </tr>
        <tr>
          <td><span class="announce_date">04:10 - 05:00 (Day+1)</span></td>
          <td class="tabletext" style="text-align: left">Audio-visual video understanding</td>
          <td class="tabletext"><a href="https://zenodo.org/record/5013725/files/Audio-visual%20video%20understanding.pptx?download=1"  target="_blank">[Slides]</a>&nbsp<a href="https://zenodo.org/record/5078777/files/yapeng.mp4?download=1"  target="_blank">[Recording]</a></td>
          <td class="tabletext"><a href="http://yapengtian.org/"  target="_blank">Yapeng Tian</a></td>
        </tr>
        <tr>
          <td><span class="announce_date">05:00 - 05:30 (Day+1)</span></td>
          <td class="tabletext" style="text-align: left">Panel Discussion</td>
          <td class="tabletext"><a href="https://zenodo.org/record/5078801/files/discussion.mp4?download=1"  target="_blank">[Recording]</a></td>
          <td></td>
        </tr>
  
  
    </tbody>
  </table>
  </div>
  
  <div  id="CET" class="tabcontent" style ="width:100%">
    <table class="alt">
        <tbody>
          <col width="18%">
          <col width="39%">
          <col width="23%">
          <col width="20%">
            <tr>
                <td><span class="announce_date">16:00 - 16:05</span></td>
                <td class="tabletext" style="text-align: left">Welcome</td>
                <td class="tabletext"><a href="https://zenodo.org/record/5013725/files/Welcome.pptx?download=1"  target="_blank">[Slides]</a></td>
                <td class="tabletext"><a href="https://www.cs.rochester.edu/~cxu22/"  target="_blank">Chenliang Xu</a></td>
            </tr>
            <tr>
              <td><span class="announce_date">16:05 - 16:55</span></td>
              <td class="tabletext" style="text-align: left">  Neuroscience in audio-visual perception</td>
              <td class="tabletext"><a href="https://zenodo.org/record/5013725/files/Neuroscience%20in%20audio-visual%20perception.pptx?download=1"  target="_blank">[Slides]</a>&nbsp<a href="https://zenodo.org/record/5078845/files/ross.mp4?download=1"  target="_blank">[Recording]</a></td>
              <td class="tabletext"><a href="https://www.urmc.rochester.edu/labs/maddox.aspx"  target="_blank">Ross K. Maddox</a></td>
          </tr>
          <tr>
            <td><span class="announce_date">16:55 - 17:45</span></td>
            <td class="tabletext" style="text-align: left">Audio scene understanding</td>
            <td class="tabletext"><a href="https://zenodo.org/record/5013725/files/Audio%20scene%20understanding.pdf?download=1"  target="_blank">[Slides]</a>&nbsp<a href="https://zenodo.org/record/5078889/files/zhiyao.mp4?download=1"  target="_blank">[Recording]</a></td>
            <td class="tabletext"><a href="http://www2.ece.rochester.edu/~zduan/"  target="_blank">Zhiyao Duan</a></td>
        </tr>
        <tr>
          <td><span class="announce_date">17:45 - 18:35</span></td>
          <td class="tabletext" style="text-align: left">Audio visual scene-aware dialog based on human perspective scene understanding</td>
          <td class="tabletext"><a href="https://zenodo.org/record/5077829/files/Human-perspective_Scene-understanding%40CVPR2021-open.pdf?download=1"  target="_blank">[Slides]</a>&nbsp<a href="https://zenodo.org/record/5078937/files/chiori.mp4?download=1"  target="_blank">[Recording]</a></td>
          <td class="tabletext" ><a href="https://www.merl.com/people/chori"  target="_blank">Chiori Hori</a></td>
        </tr>
        <tr>
          <td><span class="announce_date">18:35 - 19:25</span></td>
          <td class="tabletext" style="text-align: left">Audio-visual self-supervised learning</td>
          <td class="tabletext"><a href="https://zenodo.org/record/5013725/files/Audio-visual%20self-supervised%20learning.pdf?download=1"  target="_blank">[Slides]</a>&nbsp<a href="https://zenodo.org/record/5078950/files/di.mp4?download=1"  target="_blank">[Recording]</a></td>
          <td class="tabletext"><a href="https://dtaoo.github.io/"  target="_blank">Di Hu</a></td>
        </tr>
        <tr>
          <td><span class="announce_date">19:25 - 19:40</span></td>
          <td class="tabletext" style="text-align: left">Coffee Break</td>
          <td></td>
          <td class="tabletext"></td>
        </tr>
        <tr>
          <td><span class="announce_date">19:40 - 20:30</span></td>
          <td class="tabletext" style="text-align: left">Natural interaction with audiovisual messages</td>
          <td class="tabletext"><a href="https://zenodo.org/record/5077833/files/CVPR_Amir_Main.pdf?download=1"  target="_blank">[Slides]</a>&nbsp<a href="https://zenodo.org/record/5078610/files/amir.mp4?download=1"  target="_blank">[Recording]</a></td>
          <td class="tabletext"><a href="https://www.amir-zadeh.com/"  target="_blank">Amir Zadeh</a></td>
        </tr>
        <tr>
          <td><span class="announce_date">20:30 - 21:20</span></td>
          <td class="tabletext" style="text-align: left">Audio-visual sound source localization and separation</td>
          <td class="tabletext"><a href="https://zenodo.org/record/5078654/files/chuang.mp4?download=1"  target="_blank">[Recording]</a></td>
          <td class="tabletext"><a href="https://people.csail.mit.edu/ganchuang/"  target="_blank">Chuang Gan</a></td>
        </tr>
        <tr>
          <td><span class="announce_date">21:20 - 22:10</span></td>
          <td class="tabletext" style="text-align: left">Audio-visual cross-modal generation</td>
          <td class="tabletext"><a href="https://zenodo.org/record/5013725/files/Audio-visual%20cross-modal%20generation.pptx?download=1"  target="_blank">[Slides]</a>&nbsp<a href="https://zenodo.org/record/5078731/files/lele.mp4?download=1"  target="_blank">[Recording]</a></td>
          <td class="tabletext"><a href="https://www.cs.rochester.edu/u/lchen63/"  target="_blank">Lele Chen</a></td>
        </tr>
        <tr>
          <td><span class="announce_date">22:10 - 23:00</span></td>
          <td class="tabletext" style="text-align: left">Audio-visual video understanding</td>
          <td class="tabletext"><a href="https://zenodo.org/record/5013725/files/Audio-visual%20video%20understanding.pptx?download=1"  target="_blank">[Slides]</a>&nbsp<a href="https://zenodo.org/record/5078777/files/yapeng.mp4?download=1"  target="_blank">[Recording]</a></td>
          <td class="tabletext"><a href="http://yapengtian.org/"  target="_blank">Yapeng Tian</a></td>
        </tr>
        <tr>
          <td><span class="announce_date">23:00 - 23:30</span></td>
          <td class="tabletext" style="text-align: left">Panel Discussion</td>
          <td class="tabletext"><a href="https://zenodo.org/record/5078801/files/discussion.mp4?download=1"  target="_blank">[Recording]</a></td>
          <td></td>
        </tr>
  
  
    </tbody>
  </table>
  </div>





<br>

</div>



<!--
<h2 id="time-and-location">Time and Location</h2>
<p>June 17, 2019. 9:00 am - 12:30 pm. Room 203A</p>

<h2 id="tutorial-schedule">Tutorial Schedule</h2>

<ul>
  <li>9:00 am - 9:10 am : Introduction (Nikhil Naik)</li>
  <li>9:10 am - 9:55 am : Few-shot meta-learning (Chelsea Finn)</li>
  <li>9:55 am - 10:40 am : Multi-task learning and meta-learning (Nitish Keskar)</li>
  <li>10:40 am - 11:00 am : Coffee Break</li>
  <li>11:00 am - 11:45 am: Neural Architecture Search (Nikhil Naik)</li>
  <li>11:45 am - 12:30 am: Bayesian Optimization and Meta-learning (Frank Hutter)</li>
</ul>


      <footer class="site-footer">
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
      </footer>
    </section>

  

  <div class="container">
    <h2>Organizers</h2>
      <div>
  
        <div class="instructor">
        <a href="https://dtaoo.github.io/"  target="_blank">
        <div class="instructorphoto"><img src="https://i.postimg.cc/ncrfsmC7/dihu.jpg" width="20%" hspace="2%">   </div>  
        <div>Di Hu<br><small>Renmin University of China</small></div></a>
  
        </div>
    
        <div class="instructor">
                <a href="http://yapengtian.org/"  target="_blank">
  
        <div class="instructorphoto"><img src="https://i.postimg.cc/NFfqk9D3/yapeng.jpg" width="20%" hspace="2%">  </div> 
        <div>Yapeng Tian<br><small>University of Rochester</small></div></a>
  
        </div>
  
        <div class="instructor">
                <a href="https://www.cs.rochester.edu/u/lchen63/"  target="_blank">
  
        <div class="instructorphoto"><img src="https://i.postimg.cc/L5CdC90n/Lele.jpg" width="20%" hspace="2%"> </div>
        <div>Lele Chen<br><small>University of Rochester</small></div></a>
  
        </div>
  
        <div class="instructor">
                <a href="https://www.amir-zadeh.com/"  target="_blank">
  
        <div class="instructorphoto"><img src="https://i.postimg.cc/85bgvBRd/Amir.jpg" width="20%" hspace="2%"></div>
        <div>Amir Zadeh<br><small>Carnegie Mellon University</small></div></a>
        </div>
  
        <div class="instructor">
                <a href="http://www2.ece.rochester.edu/~zduan/"  target="_blank">
  
        <div class="instructorphoto"><img src="https://i.postimg.cc/764ybQ2Y/duan.jpg" width="20%" hspace="2%">     </div>
        <div>Zhiyao Duan<br><small>University of Rochester</small></div></a>
        </div>
    
        <div class="instructor">
                <a href="https://www.urmc.rochester.edu/labs/maddox.aspx"  target="_blank">
  
        <div class="instructorphoto"><img src="https://i.postimg.cc/HLXgYCjh/ross.jpg" width="20%" hspace="2%"></div>   
        <div>Ross K. Maddox<br><small>University of Rochester</small></div></a>
  
      </div>
  
      <div class="instructor">
        <a href="https://www.cs.rochester.edu/~cxu22/"  target="_blank">
  
      <div class="instructorphoto"><img src="https://i.postimg.cc/1RJZ5B5s/xu.jpg" width="20%" hspace="2%"></div>   
    <div>Chenliang Xu<br><small>University of Rochester</small></div></a>
      </div>
  
  
  
  
  
  </div>
-->
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>


  <script>
    //openCity(event, 'PST');
    document.getElementById("default_button").click(); // Click on the checkbox
    function openCity(evt, cityName) {
      // Declare all variables
      var i, tabcontent, tablinks;
    
      // Get all elements with class="tabcontent" and hide them
      tabcontent = document.getElementsByClassName("tabcontent");
      for (i = 0; i < tabcontent.length; i++) {
        tabcontent[i].style.display = "none";
      }
    
      // Get all elements with class="tablinks" and remove the class "active"
      tablinks = document.getElementsByClassName("tablinks");
      for (i = 0; i < tablinks.length; i++) {
        tablinks[i].className = tablinks[i].className.replace(" active", "");
      }
    
      // Show the current tab, and add an "active" class to the button that opened the tab
      document.getElementById(cityName).style.display = "block";
      evt.currentTarget.className += " active";
    }
    
    </script>
  </body>
</html>
